{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "AdversarialAttackOnFaceRecognition.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9hw4CNW4NlB"
   },
   "source": [
    "# Face recognition model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rv9kz3Q5aRCM"
   },
   "source": [
    "## Import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OF5Tzs62YTYe"
   },
   "source": [
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import statistics\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "\n",
    "import keras \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rrw_NjMgazXc"
   },
   "source": [
    "## Download Kaggle datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jKxlXL1QZ_CA"
   },
   "source": [
    "!mkdir .kaggle\n",
    "\n",
    "token = {\"username\":\"arbenamusa\",\"key\":\"2e2a2c05c2bbf4867a1d729b6cb9a1e8\"}\n",
    "with open('/content/.kaggle/kaggle.json','w') as file:\n",
    "    json.dump(token,file)\n",
    "\n",
    "!mkdir ~/.kaggle\n",
    "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle config set -n path -v{/content}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tnc2gcztdFur"
   },
   "source": [
    "Mund të kërkojmë dhe listojmë datasete specifike të cilat ekzistojnë në Kaggle.\n",
    "\n",
    "\n",
    "> ```\n",
    "!kaggle datasets list -s face\n",
    "```\n",
    "\n",
    "> -s është shkurtes për search."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YEt12cEkaGfH"
   },
   "source": [
    "!kaggle datasets download -d dansbecker/5-celebrity-faces-dataset -p/content/ziped_dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "112prB_XaIT1"
   },
   "source": [
    "dataset = \"/content/ziped_dataset/5-celebrity-faces-dataset.zip\"\n",
    "\n",
    "with zipfile.ZipFile(dataset, 'r') as z:\n",
    "    z.extractall('/content/datasets/5-celebrity-faces-dataset') "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0lZvVc4g3n-"
   },
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uzVRCkrmkUwU"
   },
   "source": [
    "train_data_dir = '/content/datasets/5-celebrity-faces-dataset/data/train'\n",
    "validation_data_dir = '/content/datasets/5-celebrity-faces-dataset/data/val'\n",
    "test_data_dir = '/content/datasets/5-celebrity-faces-dataset/val'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KmvU11UWkp3l"
   },
   "source": [
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_samples = 93\n",
    "validation_samples = 25\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "numclasses = 5\n",
    "labels = ['ben_afflek',  'elton_john',  'jerry_seinfeld',  'madonna',  'mindy_kaling']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edbG1JmokioS"
   },
   "source": [
    "### Image preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M98Y2ijHskX5"
   },
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1. / 255,\n",
    "                                   rotation_range = 10,\n",
    "                                   zoom_range = 0.1,\n",
    "                                   width_shift_range = 0.1,\n",
    "                                   height_shift_range = 0.1,\n",
    "                                   vertical_flip = False,\n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size = (img_width, img_height),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    class_mode = 'categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size = (img_width, img_height),\n",
    "                                                        batch_size = batch_size,\n",
    "                                                        class_mode = 'categorical')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JJ1npqL21eSP"
   },
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TKLZ6k__CYJO"
   },
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(img_width, img_height))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img /= 255.\n",
    "    return img"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkY2KpLE1a7a"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WJBN-JDyCdjv"
   },
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape = input_shape)\n",
    "flatten_layer = keras.layers.Flatten(input_shape = base_model.output_shape[1:])\n",
    "relu_dense_layer = Dense(4096, activation = 'relu')\n",
    "dropout_layer = Dropout(0.5)\n",
    "relu_dense_layer2 = Dense(4096, activation = 'relu')\n",
    "softmax_dense_layer = Dense(numclasses, activation = 'softmax')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2NC5sAhRSmRY"
   },
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(flatten_layer)\n",
    "top_model.add(relu_dense_layer)\n",
    "top_model.add(dropout_layer)\n",
    "top_model.add(relu_dense_layer2)\n",
    "top_model.add(dropout_layer)\n",
    "top_model.add(softmax_dense_layer)\n",
    "\n",
    "model = Model(inputs = base_model.input, outputs = top_model(base_model.output))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HBOqcek71msb"
   },
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(learning_rate = 1e-5, decay = 1e-7),\n",
    "              metrics = ['accuracy'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOmMzrCJ1z1p"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_PdeuB0v12QL"
   },
   "source": [
    "modelHistory = model.fit(train_generator,\n",
    "                         steps_per_epoch = train_samples // batch_size,\n",
    "                         epochs = epochs,\n",
    "                         validation_data = validation_generator,\n",
    "                         validation_steps = validation_samples // batch_size)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Iuu6tTtzWuf"
   },
   "source": [
    "Mund të ruajmë peshat e modelit\n",
    "\n",
    "```\n",
    "model.save_weights('model_weights.h5')\n",
    "```\n",
    "\n",
    "ose tërë modelin.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "model.save('model.h5')\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmjdiyK6z-CM"
   },
   "source": [
    "#### Model training history"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2w8eUrpB16x5"
   },
   "source": [
    "validation_loss = modelHistory.history['val_loss']\n",
    "training_loss = modelHistory.history['loss']\n",
    "\n",
    "epoch_count = range(1, len(validation_loss) + 1)\n",
    "fig=plt.figure(figsize = (12, 4))\n",
    "\n",
    "fig.add_subplot(121)\n",
    "plt.plot(epoch_count, validation_loss, 'm-')\n",
    "plt.plot(epoch_count, training_loss, 'b-')\n",
    "plt.legend(['Humbjet e validimit', 'Humbjet e trajnimit'])\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Humbja')\n",
    "\n",
    "val_acc = modelHistory.history['val_accuracy']\n",
    "training_acc = modelHistory.history['accuracy']\n",
    "\n",
    "epoch_count = range(1, len(val_acc) + 1)\n",
    "\n",
    "fig.add_subplot(122)\n",
    "plt.plot(epoch_count, val_acc, 'm-')\n",
    "plt.plot(epoch_count, training_acc, 'b-')\n",
    "plt.legend(['Saktësia e validimit', 'Saktësia e trajnimit'])\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Saktësia')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Numri i epokave {}.\".format(epochs))\n",
    "print(\"Mesatarja e saktësisë nëpër epoka {:.2f}%\".format(statistics.mean(val_acc)*100))\n",
    "print(\"Minimumi i saktësië nëpër epoka {:.2f}%\".format(min(val_acc)*100))\n",
    "print(\"Maksimumi i saktësië nëpër epoka {:.2f}%\".format(max(val_acc)*100))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_S2yUH2wyG_F"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t44IA2weQnDL"
   },
   "source": [
    "!mkdir /content/tests\n",
    "!mkdir /content/tests/ben_afflek\n",
    "!mkdir /content/tests/elton_john\n",
    "!mkdir /content/tests/jerry_seinfeld\n",
    "!mkdir /content/tests/madonna\n",
    "!mkdir /content/tests/mindy_kaling"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oFs0M_LONqx9"
   },
   "source": [
    "def show_predicted_image(imag, path):\n",
    "    image.save_img(\"/content/tests/\" + path, imag[0])\n",
    "\n",
    "    model_prediction = model(imag)\n",
    "    model_result = np.squeeze(model_prediction)\n",
    "    max_result = np.argmax(model_result)\n",
    "\n",
    "    img = cv2.imread(\"/content/tests/\" + path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.axis('off')\n",
    "    plt.title('{} : {:.2f}% '.format(labels[max_result], model_result[max_result]*100))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CB-RWo87x1h9"
   },
   "source": [
    "img_path = os.path.join(test_data_dir, 'madonna/httpassetsrollingstonecomassetsarticlemadonnadavidbowiechangedthecourseofmylifeforeversmallsquarexmadonnabowiejpg.jpg')\n",
    "input_image = preprocess_image(img_path4)\n",
    "\n",
    "show_predicted_image(input_image, \"madonna/madonna.png\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L16d8Y8RtslN"
   },
   "source": [
    "# Fast Gradient Sign Method"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tx2DO2tq3-ga"
   },
   "source": [
    "def FGSM(clean_image, epsilon, label, targeted):\n",
    "\n",
    "    model_prediction = model(clean_image)\n",
    "    loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    target_label = tf.one_hot(label, model_prediction.shape[-1])\n",
    "    target_label = tf.reshape(target_label, (1, model_prediction.shape[-1]))\n",
    "\n",
    "    tensor_image = tf.convert_to_tensor(clean_image)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(tensor_image)\n",
    "        prediction = model(tensor_image)\n",
    "        loss = loss_object(target_label, prediction)\n",
    "\n",
    "    gradient = tape.gradient(loss, tensor_image)\n",
    "    perturbation = tf.sign(gradient)\n",
    "    \n",
    "    if(targeted):\n",
    "      adversarial_image = clean_image - epsilon*perturbation\n",
    "    else:\n",
    "      adversarial_image = clean_image + epsilon*perturbation\n",
    "    \n",
    "    adversarial_image = tf.clip_by_value(adversarial_image, -1, 1)\n",
    "\n",
    "    return adversarial_image"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0DXpBIuz4A4h",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "epsilon = 0.04\n",
    "adversarial_image_targeted = FGSM(input_image, epsilon, 0, True)\n",
    "adversarial_image_untargeted = FGSM(input_image, epsilon, 3, False)\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
